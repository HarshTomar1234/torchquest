{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Class\n",
        "\n",
        "The Dataset class is essentially a blueprint. When you create a\n",
        "custom Dataset, you decide how data is loaded and returned.\n",
        "\n",
        "It defines:\n",
        "\n",
        "• __init__()-->  which tells how data should be loaded.\n",
        "\n",
        "• __len__()-->  which returns the total number of samples.\n",
        "\n",
        "• __getitem__(index)-->  which returns the data (and label) at the\n",
        "  given index.\n"
      ],
      "metadata": {
        "id": "WRxJ0M_znN_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader Class\n",
        "\n",
        "The DataLoader wraps a Dataset and handles batching, shuffling,\n",
        "and parallel loading for you.\n",
        "\n",
        "### DataLoader Control Flow:\n",
        "\n",
        "• At the start of each epoch, the DataLoader (if shuffle=True)\n",
        "shuffles indices(using a sampler).\n",
        "\n",
        "• It divides the indices into chunks of batch_size.\n",
        "\n",
        "• for each index in the chunk, data samples are fetched from\n",
        "the Dataset object\n",
        "\n",
        "• The samples are then collected and combined into a batch\n",
        "(using collate_fn)\n",
        "\n",
        "• The batch is returned to the main training loop"
      ],
      "metadata": {
        "id": "5itLahaWoDHA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TgAOwS2a3Keb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a synthetic classification dataset using sklearn\n",
        "X, y = make_classification(\n",
        "    n_samples=10,       # Number of samples\n",
        "    n_features=2,       # Number of features\n",
        "    n_informative=2,    # Number of informative features\n",
        "    n_redundant=0,      # Number of redundant features\n",
        "    n_classes=2,        # Number of classes\n",
        "    random_state=42     # For reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "aqEej4GC3UyT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WywhcnAj3Yec",
        "outputId": "426fc046-a2fe-4cd1-bc46-aca358494c00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.06833894, -0.97007347],\n",
              "       [-1.14021544, -0.83879234],\n",
              "       [-2.8953973 ,  1.97686236],\n",
              "       [-0.72063436, -0.96059253],\n",
              "       [-1.96287438, -0.99225135],\n",
              "       [-0.9382051 , -0.54304815],\n",
              "       [ 1.72725924, -1.18582677],\n",
              "       [ 1.77736657,  1.51157598],\n",
              "       [ 1.89969252,  0.83444483],\n",
              "       [-0.58723065, -1.97171753]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBb4gaS_3cYe",
        "outputId": "da902561-3c2e-45a3-a982-1b79afc289ce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAAejfi23fkA",
        "outputId": "af1e0cda-4c30-45f9-9f7b-f5e1272d5e66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZI0UX7R3f4H",
        "outputId": "c45b7eda-cf8b-4559-febf-58f1774e02d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "hm8_V0OQ3hby"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8b5_oEF8ejn",
        "outputId": "af98545e-b3d7-498e-f91d-c3483e367b99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0683, -0.9701],\n",
              "        [-1.1402, -0.8388],\n",
              "        [-2.8954,  1.9769],\n",
              "        [-0.7206, -0.9606],\n",
              "        [-1.9629, -0.9923],\n",
              "        [-0.9382, -0.5430],\n",
              "        [ 1.7273, -1.1858],\n",
              "        [ 1.7774,  1.5116],\n",
              "        [ 1.8997,  0.8344],\n",
              "        [-0.5872, -1.9717]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkxag9k-8gQh",
        "outputId": "95a3b7d4-9e16-47f4-a9e7-84c7533e55e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7nm0KeiA3lxj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return self.features.shape[0] # no. of rows\n",
        "\n",
        "  def __getitem__(self, index):    # in this you can also apply transformations\n",
        "\n",
        "    return self.features[index], self.labels[index]"
      ],
      "metadata": {
        "id": "_WdH2NCq4zLD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)"
      ],
      "metadata": {
        "id": "mbEXolf88_zV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCMLR4fH9Fvo",
        "outputId": "b5abc095-4af5-411d-bfb4-b7ecc22860a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUpEROQr9NXs",
        "outputId": "099e0d65-5bc2-43a7-b36f-1a96131ec33d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.8954,  1.9769]), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "0v4w5dki9QDu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features)\n",
        "  print(batch_labels)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AE9Ji0l9gVB",
        "outputId": "1c0af38f-8568-4d11-86ae-858fc15455ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0683, -0.9701],\n",
            "        [-1.1402, -0.8388]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[-2.8954,  1.9769],\n",
            "        [-0.7206, -0.9606]])\n",
            "tensor([0, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[-1.9629, -0.9923],\n",
            "        [-0.9382, -0.5430]])\n",
            "tensor([0, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.7273, -1.1858],\n",
            "        [ 1.7774,  1.5116]])\n",
            "tensor([1, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.8997,  0.8344],\n",
            "        [-0.5872, -1.9717]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zj4MdNzp9riC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lREICQsuOFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader's Sampler and collate_fn in PyTorch\n",
        "\n",
        "The PyTorch `DataLoader` class is a powerful utility for batch loading data during model training and evaluation. Two of its important parameters are `sampler` and `collate_fn`, which give you fine-grained control over how data is processed.\n",
        "\n",
        "## Sampler\n",
        "\n",
        "The `sampler` parameter controls the strategy for sampling data from your dataset.\n",
        "\n",
        "### What it does:\n",
        "- Determines the order in which data is accessed\n",
        "- Controls which samples are selected in each epoch\n",
        "- Returns indices that the DataLoader uses to retrieve items from the dataset\n",
        "\n",
        "### Built-in samplers:\n",
        "- `RandomSampler`: Samples elements randomly, with or without replacement\n",
        "- `SequentialSampler`: Samples elements sequentially, always in the same order\n",
        "- `SubsetRandomSampler`: Samples randomly from a predefined list of indices\n",
        "- `WeightedRandomSampler`: Samples according to specified weights (useful for class imbalance)\n",
        "- `BatchSampler`: Wraps another sampler to yield batches of indices\n",
        "\n",
        "### Example usage:\n",
        "```python\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "\n",
        "# Random sampling\n",
        "sampler = RandomSampler(dataset)\n",
        "dataloader = DataLoader(dataset, sampler=sampler, batch_size=32)\n",
        "\n",
        "# For handling class imbalance with weighted sampling\n",
        "weights = [1.0 if label == 0 else 5.0 for _, label in dataset]\n",
        "sampler = WeightedRandomSampler(weights, len(weights))\n",
        "dataloader = DataLoader(dataset, sampler=sampler, batch_size=32)\n",
        "```\n",
        "\n",
        "## collate_fn\n",
        "\n",
        "The `collate_fn` parameter is a function that specifies how to combine individual samples into a batch.\n",
        "\n",
        "### What it does:\n",
        "- Takes a list of samples from your dataset\n",
        "- Processes them into a batch suitable for model input\n",
        "- Handles conversions, padding, and other transformations needed\n",
        "\n",
        "### Default behavior:\n",
        "- For tensors: stacks them along a new dimension\n",
        "- For numpy arrays: converts to tensors, then stacks\n",
        "- For numbers: converts to tensors\n",
        "- For strings/custom types: keeps them in lists\n",
        "\n",
        "### When to customize:\n",
        "- Variable-length sequences (requiring padding)\n",
        "- Mixed data types\n",
        "- Complex data structures\n",
        "- Special preprocessing for batches\n",
        "\n",
        "### Example custom collate function:\n",
        "```python\n",
        "def custom_collate(batch):\n",
        "    # Separate images and labels\n",
        "    images = [item[0] for item in batch]\n",
        "    labels = [item[1] for item in batch]\n",
        "    \n",
        "    # Stack images\n",
        "    images = torch.stack(images, 0)\n",
        "    \n",
        "    # For variable-length text data, you might pad sequences\n",
        "    # padded_labels = pad_sequence(labels, batch_first=True)\n",
        "    \n",
        "    return images, torch.tensor(labels)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=32, collate_fn=custom_collate)\n",
        "```\n",
        "\n",
        "## Practical use cases\n",
        "\n",
        "1. **Natural Language Processing**: Custom `collate_fn` for padding variable-length sequences\n",
        "2. **Imbalanced datasets**: Weighted samplers to balance class representation\n",
        "3. **Custom validation splits**: SubsetRandomSampler to train on specific data subsets\n",
        "4. **Curriculum learning**: Custom samplers that change difficulty over epochs\n",
        "\n"
      ],
      "metadata": {
        "id": "UFu30_WuuOTj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5kOzaU7vIbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  DataLoader Parameters\n",
        "\n",
        "The PyTorch `DataLoader` class is a versatile utility that manages the loading of data during model training and evaluation. Here's a comprehensive explanation of its most important parameters:\n",
        "\n",
        "## Core Parameters\n",
        "\n",
        "### `dataset` (required)\n",
        "- The dataset from which to load data\n",
        "- Must implement `__getitem__()` and `__len__()` methods\n",
        "- Can be any map-style or iterable-style dataset\n",
        "\n",
        "### `batch_size` (default=1)\n",
        "- Number of samples in each batch\n",
        "- Larger batches can speed up training but consume more memory\n",
        "- Common values: 16, 32, 64, 128, 256\n",
        "\n",
        "### `shuffle` (default=False)\n",
        "- Whether to shuffle the data at the start of each epoch\n",
        "- Set to `True` for training to prevent model from learning order-based patterns\n",
        "- Often set to `False` for validation/testing to ensure reproducibility\n",
        "\n",
        "### `sampler` (default=None)\n",
        "- Defines the strategy to draw samples from the dataset\n",
        "- If specified, `shuffle` must be `False` (they're mutually exclusive)\n",
        "- Examples: `RandomSampler`, `SequentialSampler`, `WeightedRandomSampler`\n",
        "\n",
        "### `batch_sampler` (default=None)\n",
        "- Alternative to `sampler` that returns batches of indices\n",
        "- If specified, `batch_size`, `shuffle`, `sampler`, and `drop_last` are ignored\n",
        "\n",
        "### `num_workers` (default=0)\n",
        "- Number of subprocesses for data loading\n",
        "- `0` means data is loaded in the main process\n",
        "- Increasing this can significantly speed up data loading, typically set to CPU core count\n",
        "\n",
        "### `collate_fn` (default=None)\n",
        "- Function to merge a list of samples into a mini-batch\n",
        "- Default handles most tensor and numpy array conversions\n",
        "- Custom functions needed for variable-length sequences or special preprocessing\n",
        "\n",
        "### `pin_memory` (default=False)\n",
        "- If `True`, tensors are copied to CUDA pinned memory before returning\n",
        "- Can accelerate data transfer to GPU\n",
        "- Recommended when using GPU acceleration\n",
        "\n",
        "### `drop_last` (default=False)\n",
        "- Whether to drop the last incomplete batch if dataset size isn't divisible by batch size\n",
        "- Set to `True` when batch normalization is used to avoid errors with small batches\n",
        "- Setting to `False` uses all data but may yield a smaller final batch\n",
        "\n",
        "## Additional Important Parameters\n",
        "\n",
        "### `timeout` (default=0)\n",
        "- Timeout value for collecting a batch from workers\n",
        "- `0` means no timeout\n",
        "- Useful in distributed settings to avoid hanging\n",
        "\n",
        "### `worker_init_fn` (default=None)\n",
        "- Function to set up each worker process\n",
        "- Useful for setting random seeds or worker-specific configurations\n",
        "\n",
        "### `prefetch_factor` (default=2)\n",
        "- Number of batches loaded per worker in advance\n",
        "- Higher values use more memory but can improve efficiency\n",
        "- Only used when `num_workers > 0`\n",
        "\n",
        "### `persistent_workers` (default=False)\n",
        "- If `True`, worker processes will not be shut down after a dataset has been consumed\n",
        "- Reduces the overhead of starting and stopping workers between epochs\n",
        "- Most beneficial with large datasets and many workers\n",
        "\n",
        "### `generator` (default=None)\n",
        "- Random number generator for reproducibility with shuffling\n",
        "\n",
        "## Example with Key Parameters\n",
        "\n",
        "```python\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Custom dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __getitem__(self, index):\n",
        "        # Return a sample\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        # Return dataset size\n",
        "        pass\n",
        "\n",
        "# Define DataLoader with common parameters\n",
        "dataloader = DataLoader(\n",
        "    dataset=MyDataset(),\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "```\n"
      ],
      "metadata": {
        "id": "iN93V5PmvIs-"
      }
    }
  ]
}